{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6db2ffc",
   "metadata": {},
   "source": [
    "This notebook evaluates different LLM-as-a-judge strategies for LM Compass.\n",
    "\n",
    "Reference material: https://docs.google.com/document/d/1vKkgJj6Tj-gSZ-1LUBvNQQ34gatz0RaRCWAMDegFozU/edit?tab=t.0#heading=h.jo95wu3e9n0z (Prompt­-based Rubric Scoring, Multi-Agent Self Reflection, Rationale‑Based Self‑Critique Loops)\n",
    "\n",
    "Also see our proposed algorithm for judging: https://docs.google.com/document/d/1oDZiobHY0ze7zyKv1oRim8qLS9VL1oiLWeWElbhV6RI/edit?usp=sharing\n",
    "\n",
    "The goal is to compare various methods against each other and against simply using a single model's output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54da32d6",
   "metadata": {},
   "source": [
    "General prompt -> evaluation flow:\n",
    "0. Select n model candidates M (n = 2 to 4)\n",
    "1. Call OpenRouter API on initial input query Q to M candidates (in parallel, async function required probably)\n",
    "2. Store all responses R_0..R_n\n",
    "3. Pick an evaluation method\n",
    "4. Initialize judge(s) based on evaluation method\n",
    "5. Compare the judges evaluation to a baseline LLM (e.g. Base GPT-4o vs. GPT-4o Judge)\n",
    "\n",
    "Example of evaluation comparison\n",
    "1. User submits query\n",
    "2. Query gets passed to GPT-4o and Deepseek (A & B)\n",
    "3. We pick our proposed algorithm for evaluation (see above)\n",
    "3.1 Response A gets sent to Judge B. Response B gets sent to Judge A.\n",
    "3.2 Given a generic judging prompt, they determine a score\n",
    "3.3 The returned response is the response with the higher score (as long as it passes threshold, see above linked document)\n",
    "4. Return the 'winning' response\n",
    "5. Find metrics or reasons for effectiveness of this approach\n",
    "6. Repeat for other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a23bfbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74acda0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "if not OPENROUTER_API_KEY:\n",
    "    raise ValueError(\"OPENROUTER_API_KEY not found in .env file or environment variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9189a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=OPENROUTER_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43b00259",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_models = {\n",
    "    # Free Models\n",
    "    \"MiniMax: MiniMax M2 (free)\"          : \"minimax/minimax-m2:free\",\n",
    "    \"TNG: DeepSeek R1T2 Chimera (free)\"   : \"tngtech/deepseek-r1t2-chimera:free\",\n",
    "    \"Meta: Llama 3.3 70B Instruct (free)\" : \"meta-llama/llama-3.3-70b-instruct:free\",\n",
    "    \"OpenAI: gpt-oss-20b (free)\"          : \"openai/gpt-oss-20b:free\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72eeda70",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def query_model(model: str, query: str, role=\"user\"):\n",
    "    try:\n",
    "        response = await client.chat.completions.create(\n",
    "            model=candidate_models[model],\n",
    "            messages=[{\"role\" : role, \"content\" : query}],\n",
    "            temperature=1\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        return candidate_models[model], content\n",
    "    except Exception as e:\n",
    "        return candidate_models[model], str(e)\n",
    "\n",
    "async def query_models(models: list[str], queries: list[str], role=\"user\"):\n",
    "    coroutines = [query_model(models[i], queries[i], role=role) for i in range(len(models))]\n",
    "    results = await asyncio.gather(*coroutines)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2757c09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('minimax/minimax-m2:free',\n",
      "  'Green. That’s the color most people see because of chlorophyll, the pigment '\n",
      "  'that reflects green light. Depending on lighting, season, or health, grass '\n",
      "  'can look different—more yellow/brown if stressed or dry, or lighter/darker '\n",
      "  'shades.'),\n",
      " ('meta-llama/llama-3.3-70b-instruct:free',\n",
      "  \"The color of grass is typically green! However, it's worth noting that the \"\n",
      "  'exact shade of green can vary depending on factors such as the type of '\n",
      "  'grass, the amount of sunlight it receives, and the time of year. Some '\n",
      "  'grasses can also take on a more yellowish or brownish hue during times of '\n",
      "  \"drought or when they're dormant. But in general, green is the color most \"\n",
      "  'people associate with grass!')]\n"
     ]
    }
   ],
   "source": [
    "user_query = \"What color is grass?\"\n",
    "models_to_use = [\"MiniMax: MiniMax M2 (free)\", \"Meta: Llama 3.3 70B Instruct (free)\"]\n",
    "result = await query_models(models_to_use, [user_query]*len(models_to_use))\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a831a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
