{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f18d673",
   "metadata": {},
   "source": [
    "# Rationale-Based Self-Critique Loops (RL4F)\n",
    "\n",
    "**Key idea:** After initial grading, generate a *critique* of the grade in natural language, then allow the model to revise its score in a second pass.\n",
    "\n",
    "### Mechanics\n",
    "\n",
    "1. **Grade Prompt**  \n",
    "   > “Here is your score and rationale.”\n",
    "\n",
    "2. **Critique Prompt**  \n",
    "   > “Critique your previous rationale: were you too harsh or lenient?”\n",
    "\n",
    "3. **Revision**  \n",
    "   > “Based on your critique, update the score and rationale.”\n",
    "\n",
    "**Effect:** Mimics human feedback loops; shown to improve output quality across generation tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5deb2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_based_evaluator import PromptBasedEvaluator\n",
    "\n",
    "class RL4FEvaluator(PromptBasedEvaluator):\n",
    "    def __init__(self,*model_names):\n",
    "        super().__init__(*model_names)\n",
    "    \n",
    "    async def evaluate(self, user_query, rubric, iterations=2):\n",
    "        await self.n_sq_evaluate(user_query, rubric)\n",
    "        # await self.n_evaluate(user_query, rubric)\n",
    "\n",
    "        # TODO: implement iterations-based self-critique loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab4a2d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got user query answers.\n",
      "Got scoring results.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "user_query = \"How many gigabytes of VRAM should I have for 1080p gaming?\"\n",
    "\n",
    "rubric = \"\"\"Correctness & Accuracy (25 points) — Ensures claims are factually accurate and verifiable, addressing the most critical concern of hallucination-free responses. This is weighted highest because inaccurate information undermines all other qualities.\n",
    "\n",
    "Completeness (20 points) - Verifies the answer addresses all aspects of the query without significant omissions. This prevents shallow or partial responses that technically answer only part of the question.\n",
    "\n",
    "Clarity & Coherence (18 points) - Assesses whether the answer is well-organized with logical flow. Research shows that coherence and relevance are strong signals of problem-solving quality.\n",
    "\n",
    "Relevance (18 points) - Ensures all information pertains to the question, avoiding tangential content that confuses the issue. This maintains focus and efficiency.\n",
    "\n",
    "Conciseness (10 points) - Rewards efficiency by penalizing unnecessary verbosity or repetition while maintaining completeness. This balances against verbose but complete responses.\n",
    "\n",
    "Appropriateness for Context (9 points) — Checks whether tone, depth, and format match what the questioner likely needs. Technical questions require different treatment than conversational ones.\"\"\"\n",
    "\n",
    "eval = RL4FEvaluator(\n",
    "    \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
    "    \"Meta: Llama 3.3 70B Instruct (free)\",\n",
    "    \"AllenAI: Molmo2 8B (free)\"\n",
    ")\n",
    "\n",
    "await eval.evaluate(user_query, rubric, iterations=2)\n",
    "table = eval.score_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bd5bc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------- USER QUERY ANSWERS --------------------------------\n",
      "\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"model\": \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
      "        \"response\": \"\\n\\nFor **1080p gaming**, the ideal VRAM (Video RAM) depends on the level of detail, game optimization, and your settings. Here's a concise breakdown:\\n\\n### **Recommended VRAM for 1080p Gaming:**\\n1. **Minimum (Low Settings/Esports):**  \\n   - **4GB:**  \\n     Works for older/less-demanding games (e.g., *CS2*, *Valorant*, *Fortnite* at competitive settings).  \\n     *Avoid for newer AAA titles*, as textures may suffer or stutter.\\n\\n2. **Sweet Spot (Medium/High Settings):**  \\n   - **6GB\\u20138GB:**  \\n     Handles **most modern AAA games** (e.g., *Cyberpunk 2077*, *Elden Ring*) smoothly at **High settings** without ray tracing.  \\n     **Examples:** NVIDIA RTX 3060 (12GB), AMD RX 6600 (8GB).\\n\\n3. **Future-Proofing/Ultra + Ray Tracing:**  \\n   - **8GB\\u201312GB:**  \\n     Required for **max settings + ray tracing** in demanding games (e.g., *Alan Wake 2*).  \\n     **Examples:** RTX 4060 Ti (8GB), RX 7600 XT (16GB), RTX 4070 (12GB).\\n\\n### **Key Considerations:**\\n- **Game Trends:** Newer titles (e.g., *Hogwarts Legacy*) often use **>8GB VRAM** even at 1080p for Ultra textures.\\n- **Ray Tracing:** Adds ~2GB VRAM overhead. Enable DLSS/FSR to reduce strain.\\n- **GPU Balance:** Pair sufficient VRAM with a GPU powerful enough to utilize it (e.g., an RTX 3050 with 8GB is weaker than an RTX 3060 with 12GB).\\n\\n### **TL;DR:**\\n- **6GB** \\u2192 *Budget-friendly* for med/high in most games.  \\n- **8GB** \\u2192 *Best overall* for high/ultra, ray tracing, and longevity.  \\n- **12GB+** \\u2192 *Overkill for pure 1080p* but safer for future titles or mods.  \\n\\nChoose a GPU with **8GB VRAM** (e.g., RX 6600, RTX 3060, Arc A750) for the best balance of price and performance at 1080p.\"\n",
      "    },\n",
      "    {\n",
      "        \"model\": \"Meta: Llama 3.3 70B Instruct (free)\",\n",
      "        \"response\": \"For 1080p gaming, the amount of VRAM (Video Random Access Memory) you need depends on several factors, including the type of games you play, the graphics settings you use, and the performance level you're aiming for. Here are some general guidelines:\\n\\n* For casual 1080p gaming (medium to low graphics settings): 2-4 GB of VRAM is sufficient. This will allow you to play most modern games at 1080p with decent frame rates (around 30-60 FPS).\\n* For more demanding 1080p gaming (high graphics settings): 6-8 GB of VRAM is recommended. This will provide a smoother gaming experience with higher frame rates (around 60-120 FPS) and more detailed graphics.\\n* For very demanding 1080p gaming (ultra-high graphics settings, high refresh rates): 8 GB or more of VRAM is ideal. This will ensure that you can play the most demanding games at high frame rates (above 120 FPS) with all the graphics bells and whistles.\\n\\nKeep in mind that these are general guidelines, and the specific VRAM requirements will vary depending on the game and your system's overall performance. Some games may require more VRAM than others, even at 1080p.\\n\\nIt's also worth noting that having more VRAM than you need won't necessarily improve performance, but it can provide a bit of future-proofing and allow you to play games at higher resolutions or with more detailed graphics settings.\\n\\nIn summary, for 1080p gaming, 6-8 GB of VRAM is a good sweet spot, but 2-4 GB can be sufficient for more casual gaming, and 8 GB or more is ideal for very demanding games.\"\n",
      "    },\n",
      "    {\n",
      "        \"model\": \"AllenAI: Molmo2 8B (free)\",\n",
      "        \"response\": \"For 1080p gaming, 4 to 8 gigabytes of VRAM is typically sufficient. However, the specific amount needed can depend on the game you're playing, your GPU type, and your overall system configuration. It's always a good idea to check the minimum system requirements for the game you're interested in playing.\"\n",
      "    }\n",
      "]\n",
      "\n",
      "\n",
      "-------------------------------- SCORING RESULTS --------------------------------\n",
      "\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"evaluated_model\": \"Meta: Llama 3.3 70B Instruct (free)\",\n",
      "        \"evaluating_model\": \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
      "        \"score\": 96,\n",
      "        \"reasoning\": \"Response demonstrates high Correctness & Accuracy (22/25) with minor underestimation of modern 1080p ultra VRAM demands, full Completeness (20/20), strong Clarity & Coherence (18/18) with structured explanation, perfect Relevance (18/18), efficient Conciseness (9/10) with slight elaboration, and appropriate technical tone (9/9). Weighted sum applies rubric priorities correctly.\"\n",
      "    },\n",
      "    {\n",
      "        \"evaluated_model\": \"AllenAI: Molmo2 8B (free)\",\n",
      "        \"evaluating_model\": \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
      "        \"score\": 96,\n",
      "        \"reasoning\": \"Response earned full Correctness & Accuracy (25/25) as VRAM recommendation aligns with industry standards, balanced points in Completeness (18/20) for missing nuances like future-proofing/settings, full marks in other rubrics for clear, focused, context-appropriate advice.\"\n",
      "    },\n",
      "    {\n",
      "        \"evaluated_model\": \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
      "        \"evaluating_model\": \"AllenAI: Molmo2 8B (free)\",\n",
      "        \"score\": 100,\n",
      "        \"reasoning\": \"The response is factually accurate about 1080p VRAM requirements, provides a complete breakdown of tiers, addresses all key considerations, is well-organized and clear, directly relevant, concise, and appropriately formatted for technical advice, thus earning the maximum possible score across all rubric dimensions.\"\n",
      "    },\n",
      "    {\n",
      "        \"evaluated_model\": \"Meta: Llama 3.3 70B Instruct (free)\",\n",
      "        \"evaluating_model\": \"AllenAI: Molmo2 8B (free)\",\n",
      "        \"score\": 95,\n",
      "        \"reasoning\": \"The candidate\\u2019s response is generally accurate and covers the VRAM requirements for different 1080p gaming scenarios; however, it lacks citation to current game examples and could mention that 8GB can future-proof towards 1440p performance. It is well-organized, directly relevant, and complete.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------------- USER QUERY ANSWERS --------------------------------\\n\\n\")\n",
    "print(str(json.dumps(eval.user_query_answers, indent=4)))\n",
    "print(\"\\n\\n-------------------------------- SCORING RESULTS --------------------------------\\n\\n\")\n",
    "print(str(json.dumps(eval.evaluation_query_answers, indent=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb4702d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Evaluated Model (Column)</th>\n",
       "      <th>TNG: DeepSeek R1T2 Chimera (free)</th>\n",
       "      <th>Meta: Llama 3.3 70B Instruct (free)</th>\n",
       "      <th>AllenAI: Molmo2 8B (free)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Judge Model (Row)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TNG: DeepSeek R1T2 Chimera (free)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta: Llama 3.3 70B Instruct (free)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AllenAI: Molmo2 8B (free)</th>\n",
       "      <td>100.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluated Model (Column)             TNG: DeepSeek R1T2 Chimera (free)  \\\n",
       "Judge Model (Row)                                                        \n",
       "TNG: DeepSeek R1T2 Chimera (free)                                  NaN   \n",
       "Meta: Llama 3.3 70B Instruct (free)                                NaN   \n",
       "AllenAI: Molmo2 8B (free)                                        100.0   \n",
       "\n",
       "Evaluated Model (Column)             Meta: Llama 3.3 70B Instruct (free)  \\\n",
       "Judge Model (Row)                                                          \n",
       "TNG: DeepSeek R1T2 Chimera (free)                                   96.0   \n",
       "Meta: Llama 3.3 70B Instruct (free)                                  NaN   \n",
       "AllenAI: Molmo2 8B (free)                                           95.0   \n",
       "\n",
       "Evaluated Model (Column)             AllenAI: Molmo2 8B (free)  \n",
       "Judge Model (Row)                                               \n",
       "TNG: DeepSeek R1T2 Chimera (free)                         96.0  \n",
       "Meta: Llama 3.3 70B Instruct (free)                        NaN  \n",
       "AllenAI: Molmo2 8B (free)                                  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab21e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
