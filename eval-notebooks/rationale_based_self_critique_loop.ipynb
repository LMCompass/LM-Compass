{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f18d673",
   "metadata": {},
   "source": [
    "# Rationale-Based Self-Critique Loops (RL4F)\n",
    "\n",
    "**Key idea:** After initial grading, generate a *critique* of the grade in natural language, then allow the model to revise its score in a second pass.\n",
    "\n",
    "### Mechanics\n",
    "\n",
    "1. **Grade Prompt**  \n",
    "   > “Here is your score and rationale.”\n",
    "\n",
    "2. **Critique Prompt**  \n",
    "   > “Critique your previous rationale: were you too harsh or lenient?”\n",
    "\n",
    "3. **Revision**  \n",
    "   > “Based on your critique, update the score and rationale.”\n",
    "\n",
    "**Effect:** Mimics human feedback loops; shown to improve output quality across generation tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0303aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_based_evaluator import PromptBasedEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5deb2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"How many gigabytes of VRAM should I have for 1080p gaming?\"\n",
    "\n",
    "rubric = \"\"\"Correctness & Accuracy (25 points) — Ensures claims are factually accurate and verifiable, addressing the most critical concern of hallucination-free responses. This is weighted highest because inaccurate information undermines all other qualities.\n",
    "\n",
    "Completeness (20 points) - Verifies the answer addresses all aspects of the query without significant omissions. This prevents shallow or partial responses that technically answer only part of the question.\n",
    "\n",
    "Clarity & Coherence (18 points) - Assesses whether the answer is well-organized with logical flow. Research shows that coherence and relevance are strong signals of problem-solving quality.\n",
    "\n",
    "Relevance (18 points) - Ensures all information pertains to the question, avoiding tangential content that confuses the issue. This maintains focus and efficiency.\n",
    "\n",
    "Conciseness (10 points) - Rewards efficiency by penalizing unnecessary verbosity or repetition while maintaining completeness. This balances against verbose but complete responses.\n",
    "\n",
    "Appropriateness for Context (9 points) — Checks whether tone, depth, and format match what the questioner likely needs. Technical questions require different treatment than conversational ones.\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
