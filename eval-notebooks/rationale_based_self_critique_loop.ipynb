{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2f18d673",
      "metadata": {},
      "source": [
        "# Rationale-Based Self-Critique Loops (RL4F)\n",
        "\n",
        "**Key idea:** After initial grading, generate a *critique* of the grade in natural language, then allow the model to revise its score in a second pass.\n",
        "\n",
        "### Mechanics\n",
        "\n",
        "1. **Grade Prompt**  \n",
        "   > “Here is your score and rationale.”\n",
        "\n",
        "2. **Critique Prompt**  \n",
        "   > “Critique your previous rationale: were you too harsh or lenient?”\n",
        "\n",
        "3. **Revision**  \n",
        "   > “Based on your critique, update the score and rationale.”\n",
        "\n",
        "**Effect:** Mimics human feedback loops; shown to improve output quality across generation tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e5deb2f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from prompt_based_evaluator import PromptBasedEvaluator\n",
        "import textwrap\n",
        "\n",
        "class RL4FEvaluator(PromptBasedEvaluator):\n",
        "    def __init__(self,*model_names):\n",
        "        super().__init__(*model_names)\n",
        "        # critique_history: list of \"rounds\". Each round is a list of dicts, one per\n",
        "        # (evaluating_model, evaluated_model), with before_*, raw_response, after_*.\n",
        "        self.critique_history = []\n",
        "\n",
        "    def format_critique_entry(self, item):\n",
        "        \"\"\"Format one critique-history entry for readable before/after display.\"\"\"\n",
        "        lines = [\n",
        "            f\"Judge: {item['evaluating_model']}  →  Candidate: {item['evaluated_model']}\",\n",
        "            \"  Before:\",\n",
        "            f\"    Score: {item['before_score']}\",\n",
        "            f\"    Reasoning: {item['before_reasoning']}\",\n",
        "            \"  Raw response (critique + revision):\",\n",
        "            \"    \" + item[\"raw_response\"].replace(\"\\n\", \"\\n    \"),\n",
        "            \"  After:\",\n",
        "            f\"    Score: {item.get('after_score')}\",\n",
        "            f\"    Reasoning: {item.get('after_reasoning')}\",\n",
        "        ]\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    def _self_critique_and_revision_prompt(self, user_query, rubric, response, reasoning, score):\n",
        "        \"\"\"\n",
        "        Combined prompt: critique your previous evaluation, then output revised\n",
        "        reasoning and score as JSON. Saves one API call per pair per iteration.\n",
        "        \"\"\"\n",
        "        return textwrap.dedent(f\"\"\"\\\n",
        "        You previously evaluated a candidate's response and gave a score with a rationale. Now critique your evaluation and then provide a revised score and rationale.\n",
        "\n",
        "        QUERY:\n",
        "        {user_query}\n",
        "\n",
        "        CANDIDATE RESPONSE (that you evaluated):\n",
        "        {response}\n",
        "\n",
        "        RUBRIC:\n",
        "        {rubric}\n",
        "\n",
        "        YOUR PREVIOUS EVALUATION:\n",
        "        - Reasoning: {reasoning}\n",
        "        - Score: {score} (out of 100)\n",
        "\n",
        "        Instructions:\n",
        "\n",
        "        1. Critique: Briefly critique your previous rationale and score. Consider whether you were too harsh or lenient, missed rubric criteria, or misapplied weightings. Be specific (e.g., \"I may have been too strict on Completeness\").\n",
        "\n",
        "        2. Revision: After your critique, output your revised evaluation as a single JSON object. You must end your response with exactly one line that is only this JSON object (no other text on that line):\n",
        "        {{\"reasoning\": \"<one-sentence revised justification referencing rubric>\", \"score\": <integer 0-100>}}\n",
        "\n",
        "        Apply the rubric strictly. Correctness & Accuracy has the highest impact on the overall score.\n",
        "        \"\"\")\n",
        "\n",
        "    async def _critique_rationale(self, user_query, rubric):\n",
        "        \"\"\"\n",
        "        For each (evaluating_model, evaluated_model) entry, ask the evaluating\n",
        "        model to critique and revise its rationale/score; update entries in place.\n",
        "        Uses batched query_models for one API call per pair.\n",
        "        \"\"\"\n",
        "        if not self.evaluation_query_answers or not self.user_query_answers:\n",
        "            return\n",
        "        response_by_model = {item[\"model\"]: item[\"response\"] for item in self.user_query_answers}\n",
        "        model_names = []\n",
        "        queries = []\n",
        "        for entry in self.evaluation_query_answers:\n",
        "            response = response_by_model.get(entry[\"evaluated_model\"], \"\")\n",
        "            reasoning = entry.get(\"reasoning\", \"\")\n",
        "            score = entry.get(\"score\", 0)\n",
        "            prompt = self._self_critique_and_revision_prompt(user_query, rubric, response, reasoning, score)\n",
        "            model_names.append(entry[\"evaluating_model\"])\n",
        "            queries.append(prompt)\n",
        "        results = await self.query_models(model_names, queries)\n",
        "        round_data = []\n",
        "        for i, entry in enumerate(self.evaluation_query_answers):\n",
        "            before_reasoning = entry.get(\"reasoning\", \"\")\n",
        "            before_score = entry.get(\"score\", 0)\n",
        "            raw = results[i][\"response\"]\n",
        "            revised = self.extract_outermost_json(raw)\n",
        "            after_reasoning = revised.get(\"reasoning\") if revised else None\n",
        "            after_score = int(revised[\"score\"]) if revised and \"score\" in revised else None\n",
        "            round_data.append({\n",
        "                \"evaluating_model\": entry[\"evaluating_model\"],\n",
        "                \"evaluated_model\": entry[\"evaluated_model\"],\n",
        "                \"before_reasoning\": before_reasoning,\n",
        "                \"before_score\": before_score,\n",
        "                \"raw_response\": raw,\n",
        "                \"after_reasoning\": after_reasoning,\n",
        "                \"after_score\": after_score,\n",
        "            })\n",
        "        self.critique_history.append(round_data)\n",
        "        for i, entry in enumerate(self.evaluation_query_answers):\n",
        "            if round_data[i][\"after_reasoning\"] is not None and round_data[i][\"after_score\"] is not None:\n",
        "                entry[\"score\"] = round_data[i][\"after_score\"]\n",
        "                entry[\"reasoning\"] = round_data[i][\"after_reasoning\"]\n",
        "\n",
        "    async def evaluate(self, user_query, rubric, iterations=2):\n",
        "        self.critique_history = []\n",
        "        # Step 1: Initial evaluation (populates user_query_answers and evaluation_query_answers)\n",
        "        await self.n_sq_evaluate(user_query, rubric)\n",
        "        # Step 2: Refine via critique-and-revision (iterations - 1 rounds)\n",
        "        for _ in range(iterations - 1):\n",
        "            await self._critique_rationale(user_query, rubric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ab4a2d14",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got user query answers.\n",
            "Got scoring results.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "user_query = \"How many gigabytes of VRAM should I have for 1080p gaming?\"\n",
        "\n",
        "rubric = \"\"\"Correctness & Accuracy (25 points) — Ensures claims are factually accurate and verifiable, addressing the most critical concern of hallucination-free responses. This is weighted highest because inaccurate information undermines all other qualities.\n",
        "\n",
        "Completeness (20 points) - Verifies the answer addresses all aspects of the query without significant omissions. This prevents shallow or partial responses that technically answer only part of the question.\n",
        "\n",
        "Clarity & Coherence (18 points) - Assesses whether the answer is well-organized with logical flow. Research shows that coherence and relevance are strong signals of problem-solving quality.\n",
        "\n",
        "Relevance (18 points) - Ensures all information pertains to the question, avoiding tangential content that confuses the issue. This maintains focus and efficiency.\n",
        "\n",
        "Conciseness (10 points) - Rewards efficiency by penalizing unnecessary verbosity or repetition while maintaining completeness. This balances against verbose but complete responses.\n",
        "\n",
        "Appropriateness for Context (9 points) — Checks whether tone, depth, and format match what the questioner likely needs. Technical questions require different treatment than conversational ones.\"\"\"\n",
        "\n",
        "eval = RL4FEvaluator(\n",
        "    \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
        "    \"StepFun: Step 3.5 Flash (free)\",\n",
        "    \"AllenAI: Molmo2 8B (free)\"\n",
        ")\n",
        "\n",
        "await eval.evaluate(user_query, rubric, iterations=2)\n",
        "table = eval.score_table()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5bd5bc91",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------- USER QUERY ANSWERS --------------------------------\n",
            "\n",
            "\n",
            "[\n",
            "    {\n",
            "        \"model\": \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
            "        \"response\": \"\\n\\nFor **1080p gaming** (1920x1080 resolution), the ideal amount of VRAM depends on the games you play, your desired graphics settings, and future-proofing. Here's a breakdown:\\n\\n### **1. Minimum: 4GB VRAM**  \\n- Can run **older or less demanding games** at medium settings (e.g., _CS:GO_, _Rocket League_, _League of Legends_).  \\n- **Not recommended** for modern AAA titles (e.g., _Cyberpunk 2077_, _Hogwarts Legacy_), as these often require 6GB+ even at 1080p.\\n\\n### **2. Recommended: 6GB VRAM**  \\n- Handles **most modern AAA games** smoothly at **medium-to-high settings**.  \\n- Still might struggle with **ultra settings or future games**, especially those using high-resolution textures.  \\n- Good budget option for casual gamers.\\n\\n### **3. Ideal: 8GB VRAM**  \\n- **Sweet spot for 1080p gaming** today.  \\n- Allows **ultra settings** in most AAA titles (e.g., _Elden Ring_, _Call of Duty: Warzone_).  \\n- Future-proof for **next 3\\u20134 years** as games demand more VRAM.  \\n- Works well with **ray tracing** (RTX/DXR) or **modded games** (texture packs).  \\n- **GPUs to consider:** NVIDIA RTX 3060 Ti, AMD RX 6600 XT, RTX 4060, RX 7600.\\n\\n### **4. Future-Proof/Enthusiast: 12GB+ VRAM**  \\n- Overkill for **current 1080p gaming** but useful for:  \\n  - **Extremely high-res textures/mods** (e.g., _Skyrim_ with 4K mods).  \\n  - **Ray tracing + max settings** without compromises.  \\n  - **Content creation** (video editing, Blender).  \\n- Examples: RTX 4070, RX 7700 XT, RTX 3080 (12GB).\\n\\n---\\n\\n### **Key Considerations**  \\n- **Game Optimization:** Poorly optimized games (e.g., _The Last of Us Part I_) may exceed 8GB even at 1080p.  \\n- **Ray Tracing:** Adds ~1\\u20132GB VRAM overhead.  \\n- **Future Games:** Titles like _GTA VI_ will likely push VRAM requirements higher.  \\n- **GPU Architecture:** Newer GPUs (e.g., NVIDIA Ada Lovelace or AMD RDNA 3) use VRAM more efficiently.\\n\\n### **Final Recommendation**  \\nAim for **8GB VRAM** (e.g., RTX 3060 Ti, RX 7600) to balance performance, settings, and longevity at 1080p. If budget allows, 12GB provides extra headroom for future titles and ray tracing. Avoid 4GB cards for modern gaming.\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"StepFun: Step 3.5 Flash (free)\",\n",
            "        \"response\": \"Excellent question! For **1080p (1920x1080) gaming in 2024 and beyond**, the recommended amount of VRAM has shifted due to increasingly detailed textures and modern rendering techniques.\\n\\nHere\\u2019s a detailed breakdown:\\n\\n### **The Short Answer (Current & Future-Proof)**\\n*   **Minimum (for older/esports titles):** **4GB** is still functional for many games at lower-to-medium settings, but it's becoming a serious limitation for new AAA releases.\\n*   **Sweet Spot (for most modern 1080p gaming):** **8GB** is the current recommended standard. It allows you to play the vast majority of games at **High to Ultra settings** without texture-related stuttering.\\n*   **Future-Proof / Comfort Buffer:** **12GB or more** is ideal for future-proofing. This ensures you can max out texture quality in new titles for years to come and comfortably use upscaling technologies (DLSS, FSR, XeSS) without worrying about VRAM limits.\\n\\n---\\n\\n### **Why More VRAM is Needed Now**\\n1.  **Texture Quality:** High-resolution textures (2K, 4K) are the biggest VRAM consumers. \\\"Ultra\\\" texture settings in modern games can easily use 6-8GB at 1080p.\\n2.  **Modern Rendering Techniques:**\\n    *   **Ray Tracing:** Increases VRAM usage due to additional data structures (like BVH).\\n    *   **Upscaling (DLSS/FSR/XeSS):** While these *save* performance, the **frame buffer** they render to still uses VRAM. A 4K upscaled frame buffer at 1080p output can use more VRAM than a native 1080p frame.\\n3.  **Game Architecture:** Open-world games (e.g., *Cyberpunk 2077*, *Starfield*, *Hogwarts Legacy*) stream assets from storage into VRAM. More VRAM means fewer pop-ins and smoother streaming.\\n\\n---\\n\\n### **Real-World Examples (1080p)**\\n*   **6GB GPU (e.g., RTX 3060, RX 6600 XT):** Can handle 1080p High settings in most games, but may require lowering **texture quality to Medium** in the newest AAA titles (2023-2024) to avoid stuttering. Works well with FSR/DLSS.\\n*   **8GB GPU (e.g., RTX 4060, RX 7700 XT):** The **best current balance**. Allows High/Ultra textures in nearly all 1080p games. Excellent for high refresh rate (144Hz+) competitive gaming with lower settings, or immersive single-player with max textures.\\n*   **12GB+ GPU (e.g., RTX 4070, RX 7800 XT):** **Overkill for pure 1080p** in terms of raw power, but the extra VRAM is a **luxury and future-proofing**. You will never have to think about texture settings, and it's perfect if you plan to move to 1440p later.\\n\\n---\\n\\n### **Special Considerations**\\n*   **Modded Games (Skyrim, Fallout 4):** High-resolution texture mods can consume **10GB+ of VRAM** even at 1080p. For modding, 12GB+ is strongly recommended.\\n*   **Competitive Esports (Valorant, CS2, Fortnite):** These games are CPU-bound and use very little VRAM (3-4GB). A 6GB card is more than enough here, and you'll prioritize high frame rates over Ultra textures.\\n*   **Video Encoding/Streaming:** While this primarily uses system RAM and the encoder (NVENC/AMF), having extra VRAM helps by leaving more headroom for the game itself.\\n\\n---\\n\\n### **Key Takeaway**\\n| Your Priority | Recommended VRAM |\\n| :--- | :--- |\\n| **Budget / Older Games** | 6GB (with awareness of limitations) |\\n| **Best Value for New AAA** | **8GB** (Target this) |\\n| **Future-Proofing / Modding** | 12GB or more |\\n| **Pure Competitive FPS** | 6GB+ (focus on GPU speed & CPU) |\\n\\n**Final Advice:** For a **new GPU purchase today intended for 1080p gaming for the next 3-4 years, aim for 8GB of VRAM as your baseline.** If your budget allows, stepping up to a 12GB card (like an RX 7800 XT or RTX 4070) gives you tremendous peace of mind and a painless path to 1440p later.\\n\\n**Check your current GPU's VRAM:** Use a tool like GPU-Z or your graphics driver control panel (NVIDIA Control Panel / AMD Adrenalin) to see how much you have and monitor usage in-game with MSI Afterburner. If you're consistently hitting 95%+ VRAM usage with texture quality turned down, it's time to upgrade.\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"AllenAI: Molmo2 8B (free)\",\n",
            "        \"response\": \"For **1080p VRAM gaming**, a **4 GB VRAM** graphics card is usually sufficient for most modern games at **high or ultra settings**. You might occasionally notice some title limitations, but 4 GB is still practical and affordable as of 2024.\\n\\nHowever, here\\u2019s a quick breakdown:\\n\\n| VRAM Size | Typical 1080p Games |\\n|-----------|----------------------|\\n| **2 GB**  | Mostly older/lightweight titles; won\\u2019t run many modern games at high settings |\\n| **4 GB**  | Most modern games at high or ultra settings; recommended |\\n| **6-8 GB** | Overkill for 1080p, but better for smoother performance in some games/titles discussed |\\n| **10+ GB** | Gaming at 1080p is only possible in the rarest high-load cases |\\n\\n**Bottom line:**  \\n**4 GB VRAM** is the sweet spot for 1080p gaming. If you want to futureproof or play big AAA titles with realistic settings, 6 GB or more is also good.\"\n",
            "    }\n",
            "]\n",
            "\n",
            "\n",
            "-------------------------------- SCORING RESULTS --------------------------------\n",
            "\n",
            "\n",
            "[\n",
            "    {\n",
            "        \"evaluated_model\": \"StepFun: Step 3.5 Flash (free)\",\n",
            "        \"evaluating_model\": \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
            "        \"score\": 98,\n",
            "        \"reasoning\": \"Minor deduction in Correctness (23/25) due to overstatement about 8GB universally handling Ultra settings in 2023-2024 AAA games at 1080p, slightly affecting factual precision; other rubric categories remain flawless.\"\n",
            "    },\n",
            "    {\n",
            "        \"evaluated_model\": \"AllenAI: Molmo2 8B (free)\",\n",
            "        \"evaluating_model\": \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
            "        \"score\": 60,\n",
            "        \"reasoning\": \"Revised score adjusts for over-penalty in Correctness: while '4GB sufficient for ultra' is inaccurate for 2024 AAA titles, the answer partially mitigates this by noting limitations/futureproofing, warranting higher Completeness/Clarity credit per rubric weights.\"\n",
            "    },\n",
            "    {\n",
            "        \"evaluated_model\": \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
            "        \"evaluating_model\": \"StepFun: Step 3.5 Flash (free)\",\n",
            "        \"score\": 95,\n",
            "        \"reasoning\": \"Deducted 3 points in Correctness & Accuracy for overstating 6GB VRAM viability in modern AAA games and 2 points in Completeness for omitting current-game examples where 6GB fails; other categories full per rubric.\"\n",
            "    },\n",
            "    {\n",
            "        \"evaluated_model\": \"AllenAI: Molmo2 8B (free)\",\n",
            "        \"evaluating_model\": \"StepFun: Step 3.5 Flash (free)\",\n",
            "        \"score\": 73,\n",
            "        \"reasoning\": \"The response is coherent and relevant but contains a key factual error in stating 4 GB VRAM suffices for 1080p high/ultra gaming in 2024, severely impacting the highest-weighted Correctness & Accuracy score, with additional minor deductions for incoherent recommendations and marginally irrelevant claims.\"\n",
            "    },\n",
            "    {\n",
            "        \"evaluated_model\": \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
            "        \"evaluating_model\": \"AllenAI: Molmo2 8B (free)\",\n",
            "        \"score\": 91,\n",
            "        \"reasoning\": \"The candidate\\u2019s response is generally both complete and accurate but misses a subtle emphasis on 1080p-specific future-proofing and may include some texture slightly beyond the primary query, across the rubric\\u2019s points it should be docked slightly less harshly than my initial assessment, considering technical thoroughness outweighs minor redundancy.\"\n",
            "    },\n",
            "    {\n",
            "        \"evaluated_model\": \"StepFun: Step 3.5 Flash (free)\",\n",
            "        \"evaluating_model\": \"AllenAI: Molmo2 8B (free)\",\n",
            "        \"score\": 96,\n",
            "        \"reasoning\": \"The candidate provides a detailed, logically structured response with well substantiated facts about VRAM requirements for 1080p gaming, correctly addressing current trends, future-proofing, and dense examples relevant to the query. The response is accurate, complete, and tailored to technical inquiries reflecting the priority of correctness per the rubric.\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "print(\"-------------------------------- USER QUERY ANSWERS --------------------------------\\n\\n\")\n",
        "print(str(json.dumps(eval.user_query_answers, indent=4)))\n",
        "print(\"\\n\\n-------------------------------- SCORING RESULTS --------------------------------\\n\\n\")\n",
        "print(str(json.dumps(eval.evaluation_query_answers, indent=4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "afb4702d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Evaluated Model (Column)</th>\n",
              "      <th>TNG: DeepSeek R1T2 Chimera (free)</th>\n",
              "      <th>StepFun: Step 3.5 Flash (free)</th>\n",
              "      <th>AllenAI: Molmo2 8B (free)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Judge Model (Row)</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TNG: DeepSeek R1T2 Chimera (free)</th>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>StepFun: Step 3.5 Flash (free)</th>\n",
              "      <td>95.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>73.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AllenAI: Molmo2 8B (free)</th>\n",
              "      <td>91.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Evaluated Model (Column)           TNG: DeepSeek R1T2 Chimera (free)  \\\n",
              "Judge Model (Row)                                                      \n",
              "TNG: DeepSeek R1T2 Chimera (free)                                NaN   \n",
              "StepFun: Step 3.5 Flash (free)                                  95.0   \n",
              "AllenAI: Molmo2 8B (free)                                       91.0   \n",
              "\n",
              "Evaluated Model (Column)           StepFun: Step 3.5 Flash (free)  \\\n",
              "Judge Model (Row)                                                   \n",
              "TNG: DeepSeek R1T2 Chimera (free)                            98.0   \n",
              "StepFun: Step 3.5 Flash (free)                                NaN   \n",
              "AllenAI: Molmo2 8B (free)                                    96.0   \n",
              "\n",
              "Evaluated Model (Column)           AllenAI: Molmo2 8B (free)  \n",
              "Judge Model (Row)                                             \n",
              "TNG: DeepSeek R1T2 Chimera (free)                       60.0  \n",
              "StepFun: Step 3.5 Flash (free)                          73.0  \n",
              "AllenAI: Molmo2 8B (free)                                NaN  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bab21e60",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Refinement round 1 ===\n",
            "Judge: TNG: DeepSeek R1T2 Chimera (free)  →  Candidate: StepFun: Step 3.5 Flash (free)\n",
            "  Before:\n",
            "    Score: 100\n",
            "    Reasoning: The response provides accurate, up-to-date VRAM recommendations for 1080p gaming (25/25 Correctness), thoroughly addresses all query aspects including edge cases like modding (20/20 Completeness), uses clear headers/logical flow (18/18 Clarity), maintains strict focus on VRAM needs (18/18 Relevance), delivers comprehensive information without fluff (10/10 Conciseness), and adopts a perfect technical-but-approachable tone (9/9 Appropriateness).\n",
            "  Raw response (critique + revision):\n",
            "    {\"reasoning\": \"Minor deduction in Correctness (23/25) due to overstatement about 8GB universally handling Ultra settings in 2023-2024 AAA games at 1080p, slightly affecting factual precision; other rubric categories remain flawless.\", \"score\": 98}\n",
            "  After:\n",
            "    Score: 98\n",
            "    Reasoning: Minor deduction in Correctness (23/25) due to overstatement about 8GB universally handling Ultra settings in 2023-2024 AAA games at 1080p, slightly affecting factual precision; other rubric categories remain flawless.\n",
            "---\n",
            "Judge: TNG: DeepSeek R1T2 Chimera (free)  →  Candidate: AllenAI: Molmo2 8B (free)\n",
            "  Before:\n",
            "    Score: 49\n",
            "    Reasoning: Correctness score heavily penalized due to the critical factual error stating 4GB VRAM is sufficient for most modern games at ultra settings in 1080p (multiple 2024 titles require 6-8GB), outweighing strengths in completeness and clarity per rubric weights.\n",
            "  Raw response (critique + revision):\n",
            "    \n",
            "    {\"reasoning\": \"Revised score adjusts for over-penalty in Correctness: while '4GB sufficient for ultra' is inaccurate for 2024 AAA titles, the answer partially mitigates this by noting limitations/futureproofing, warranting higher Completeness/Clarity credit per rubric weights.\", \"score\": 60}\n",
            "  After:\n",
            "    Score: 60\n",
            "    Reasoning: Revised score adjusts for over-penalty in Correctness: while '4GB sufficient for ultra' is inaccurate for 2024 AAA titles, the answer partially mitigates this by noting limitations/futureproofing, warranting higher Completeness/Clarity credit per rubric weights.\n",
            "---\n",
            "Judge: StepFun: Step 3.5 Flash (free)  →  Candidate: TNG: DeepSeek R1T2 Chimera (free)\n",
            "  Before:\n",
            "    Score: 99\n",
            "    Reasoning: Given the rubric's high weighting for Correctness & Accuracy (25 points), the response earns 24/25 for factual accuracy with no fundamental errors but minor optimism on 6GB handling most AAA games, and full marks in Completeness (20), Clarity & Coherence (18), Relevance (18), Conciseness (10), and Appropriateness for Context (9), summing to 99.\n",
            "  Raw response (critique + revision):\n",
            "    I was too lenient on Correctness & Accuracy by treating the 6GB recommendation as merely \"optimistic\" rather than recognizing it as factually inadequate for many current AAA titles at medium-high settings, and I missed that Completeness should have been reduced for not explicitly warning about this gap in today's market.\n",
            "    \n",
            "    {\"reasoning\": \"Deducted 3 points in Correctness & Accuracy for overstating 6GB VRAM viability in modern AAA games and 2 points in Completeness for omitting current-game examples where 6GB fails; other categories full per rubric.\", \"score\": 95}\n",
            "  After:\n",
            "    Score: 95\n",
            "    Reasoning: Deducted 3 points in Correctness & Accuracy for overstating 6GB VRAM viability in modern AAA games and 2 points in Completeness for omitting current-game examples where 6GB fails; other categories full per rubric.\n",
            "---\n",
            "Judge: StepFun: Step 3.5 Flash (free)  →  Candidate: AllenAI: Molmo2 8B (free)\n",
            "  Before:\n",
            "    Score: 79\n",
            "    Reasoning: The response contains a fundamental factual error in claiming 4 GB VRAM is sufficient for most modern games at high or ultra settings at 1080p, which is inaccurate for 2024 standards as many AAA titles require 6 GB or more, severely impacting the Correctness & Accuracy score (weighted 25 points) despite high scores in other dimensions.\n",
            "  Raw response (critique + revision):\n",
            "    I was too lenient in my initial evaluation by not sufficiently penalizing the inconsistency in the bottom line (claiming 4 GB as the sweet spot while also recommending 6 GB for futureproofing) and the misleading statement that 6-8 GB is \"overkill\" for 1080p, which affect Clarity & Coherence and Relevance. However, I correctly prioritized the fundamental factual error in the core claim about VRAM sufficiency for high/ultra settings, which is the most critical flaw given the rubric's weighting.\n",
            "    \n",
            "    {\"reasoning\": \"The response is coherent and relevant but contains a key factual error in stating 4 GB VRAM suffices for 1080p high/ultra gaming in 2024, severely impacting the highest-weighted Correctness & Accuracy score, with additional minor deductions for incoherent recommendations and marginally irrelevant claims.\", \"score\": 73}\n",
            "  After:\n",
            "    Score: 73\n",
            "    Reasoning: The response is coherent and relevant but contains a key factual error in stating 4 GB VRAM suffices for 1080p high/ultra gaming in 2024, severely impacting the highest-weighted Correctness & Accuracy score, with additional minor deductions for incoherent recommendations and marginally irrelevant claims.\n",
            "---\n",
            "Judge: AllenAI: Molmo2 8B (free)  →  Candidate: TNG: DeepSeek R1T2 Chimera (free)\n",
            "  Before:\n",
            "    Score: 93\n",
            "    Reasoning: The candidate’s response correctly categorizes VRAM needs from 4GB to >12GB with applicable examples for 1080p gaming, while mentioning relevant considerations such as game optimization, ray tracing, and future-proofing; it is factually accurate and comprehensive, well-organized, and too lengthy to call concise but still appropriate for technical guidance. Correctness (verifiable claims) is highest, giving the answer strong legitimacy and trust within its domain.\n",
            "  Raw response (critique + revision):\n",
            "    I may have been too lenient on Completeness because, while comprehensive in detail, the answer potentially contains irrelevant texture for 1080p gaming, affecting conciseness. Appropriate depth was maintained, but more precision on future-proofing would improve the overall fit.\n",
            "    \n",
            "    {\"reasoning\": \"The candidate’s response is generally both complete and accurate but misses a subtle emphasis on 1080p-specific future-proofing and may include some texture slightly beyond the primary query, across the rubric’s points it should be docked slightly less harshly than my initial assessment, considering technical thoroughness outweighs minor redundancy.\", \"score\": 91}\n",
            "  After:\n",
            "    Score: 91\n",
            "    Reasoning: The candidate’s response is generally both complete and accurate but misses a subtle emphasis on 1080p-specific future-proofing and may include some texture slightly beyond the primary query, across the rubric’s points it should be docked slightly less harshly than my initial assessment, considering technical thoroughness outweighs minor redundancy.\n",
            "---\n",
            "Judge: AllenAI: Molmo2 8B (free)  →  Candidate: StepFun: Step 3.5 Flash (free)\n",
            "  Before:\n",
            "    Score: 96\n",
            "    Reasoning: The candidate provides a detailed, logically structured response with well substantiated facts about VRAM requirements for 1080p gaming, correctly addressing current trends, future-proofing, and dense examples relevant to the query. The response is accurate, complete, and tailored to technical inquiries reflecting the priority of correctness per the rubric.\n",
            "  Raw response (critique + revision):\n",
            "    My previous assessment was overly strict in awarding an exemplary score without recognizing the inherent minor inaccuracies of the advice, such as suggesting 12GB VRAM is “ideal” for future-proofing with no citation, failing to acknowledge that memory cost increases dramatically at 12GB, and not addressing potential exceptions (e.g., VRAM consumption is not always perfectly linear with respect to game fidelity, and not all new 1080p AAA games require the same amount). Despite these gaps, the response was still primarily correct, well-elaborated, slide-up understandable, and highly relevant to the target audience.\n",
            "    \n",
            "    {\"reasoning\": \"Although the response is well-structured, highly relevant, and mostly accurate, it includes minor inaccuracies about VRAM recommendations for specific future scenarios and usage cases, and does not properly account for VRAM cost scaling or other performance factors impacting VRAM need. Low score to reflect moderate accuracy and completeness.\": \"score\": 82}\n",
            "  After:\n",
            "    Score: None\n",
            "    Reasoning: None\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# Or every round, every pair\n",
        "for round_idx, round_data in enumerate(eval.critique_history):\n",
        "    print(f\"=== Refinement round {round_idx + 1} ===\")\n",
        "    for item in round_data:\n",
        "        print(eval.format_critique_entry(item))\n",
        "        print(\"---\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
