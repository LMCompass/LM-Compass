{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f18d673",
   "metadata": {},
   "source": [
    "# Human in the Loop\n",
    "1. User provides a prompt as normal\n",
    "2. Prompt based evaluation is used to valuate the responses\n",
    "3. Get best answer\n",
    "4. Check the confidence of the answer based on how close the ratings are from each LLM\n",
    "5. If the answer is “low confidence” then take the reasonings from all different models, and ask the user which one most accurately grades the low confidence response. Then replace the averaged answer with that corresponding grade.\n",
    "6. Back to step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0303aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_based_evaluator import PromptBasedEvaluator\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5deb2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"How many gigabytes of VRAM should I have for 1080p gaming?\"\n",
    "\n",
    "rubric = \"\"\"Correctness & Accuracy (25 points) — Ensures claims are factually accurate and verifiable, addressing the most critical concern of hallucination-free responses. This is weighted highest because inaccurate information undermines all other qualities.\n",
    "\n",
    "Completeness (20 points) - Verifies the answer addresses all aspects of the query without significant omissions. This prevents shallow or partial responses that technically answer only part of the question.\n",
    "\n",
    "Clarity & Coherence (18 points) - Assesses whether the answer is well-organized with logical flow. Research shows that coherence and relevance are strong signals of problem-solving quality.\n",
    "\n",
    "Relevance (18 points) - Ensures all information pertains to the question, avoiding tangential content that confuses the issue. This maintains focus and efficiency.\n",
    "\n",
    "Conciseness (10 points) - Rewards efficiency by penalizing unnecessary verbosity or repetition while maintaining completeness. This balances against verbose but complete responses.\n",
    "\n",
    "Appropriateness for Context (9 points) — Checks whether tone, depth, and format match what the questioner likely needs. Technical questions require different treatment than conversational ones.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12422a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got user query answers.\n",
      "Got scoring results.\n"
     ]
    }
   ],
   "source": [
    "evaluator = PromptBasedEvaluator(\n",
    "    \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
    "    \"Meta: Llama 3.3 70B Instruct (free)\",\n",
    "    \"AllenAI: Molmo2 8B (free)\"\n",
    ")\n",
    "await evaluator.n_sq_evaluate(user_query, rubric)\n",
    "df = evaluator.score_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd73185b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"model\": \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
      "        \"response\": \"The amount of VRAM (Video RAM) you need for **1080p gaming** depends on the **games you play**, **graphics settings**, and **future-proofing goals**. Here's a simplified breakdown:\\n\\n### **General Recommendations**\\n1. **Minimum (Low Settings / Older Games):**  \\n   - **4GB VRAM** is the **absolute minimum** for playable 1080p gaming in less demanding or older titles (e.g., eSports games like *CS2*, *Valorant*, or indie games).  \\n   - *Downsides:* Modern AAA games will struggle, even at medium settings. Expect stuttering or texture issues.\\n\\n2. **Standard for 1080p (Medium-High Settings):**  \\n   - **6GB VRAM**: Works smoothly for most games at **medium-high settings** (e.g., *Fortnite*, *Apex Legends*, *Elden Ring*).  \\n   - *Downsides:* Newer AAA games (e.g., *Cyberpunk 2077*, *Hogwarts Legacy*) may require lowering textures or settings.\\n\\n3. **Ideal for Future-Proofing (Ultra Settings / Mods / AAA):**  \\n   - **8GB VRAM**: The **sweet spot** for max settings in most AAA games at 1080p, plus headroom for mods, higher-resolution textures, or future titles.  \\n   - *Recommended GPUs*: NVIDIA RTX 3060/4060 or AMD RX 6600 XT/7600.\\n\\n4. **Future-Proof/High-Demand Use Cases (Max Settings + Ray Tracing):**  \\n   - **12GB+ VRAM**: Ideal for **ray tracing**, ultratexture packs, or keeping your GPU viable longer (5+ years).  \\n   - *Examples:* AMD RX 6700 XT (12GB) or NVIDIA RTX 4070 (12GB).  \\n\\n---\\n\\n### **Key Considerations**\\n- **Game Requirements** \\u2192 Modern AAA games like *Alan Wake 2* or *Resident Evil 4 Remake* can exceed **8GB VRAM** even at 1080p if maxed out.\\n- **Ray Tracing** \\u2192 NVIDIA/AMD GPUs use extra VRAM for ray-traced lighting. Add **1-2GB** to your target.\\n- **Mods & Textures** \\u2192 Games like *Skyrim* or *Cyberpunk 2077* with HD texture packs may need **10GB+**.\\n- **Upscaling Tech (DLSS/FSR)** \\u2192 Reduces VRAM usage by rendering at lower resolutions, but native 1080p still demands VRAM for textures.\\n\\n---\\n\\n### **Current GPUs for 1080p Gaming**  \\n| **VRAM** | **GPU Examples**             | **Use Case**                     |\\n|----------|------------------------------|----------------------------------|\\n| **6GB**  | GTX 1660 Super, RTX 3050     | Medium settings, eSports titles  |\\n| **8GB**  | RTX 3060, RX 6600 XT, RTX 4060 | High/Ultra settings, AAA gaming  |\\n| **12GB** | RX 6700 XT, RTX 4070         | Max settings + ray tracing/future-proofing |\\n\\n---\\n\\n### **Conclusion**\\n- **Budget Option:** 6GB (if you play older/less demanding games).  \\n- **Best Value:** **8GB** for high settings in modern titles.  \\n- **Future-Ready:** **12GB+** for AAA games with ray tracing or long-term use.  \\n\\nNewer games are pushing VRAM requirements higher, so **8GB is strongly recommended** for a smooth 1080p experience in 2024 and beyond.\"\n",
      "    },\n",
      "    {\n",
      "        \"model\": \"Meta: Llama 3.3 70B Instruct (free)\",\n",
      "        \"response\": \"For 1080p gaming, the amount of VRAM (Video Random Access Memory) you need depends on several factors, including the type of games you play, the graphics settings you use, and the performance level you're aiming for. Here are some general guidelines:\\n\\n* For casual 1080p gaming (medium to low graphics settings): 2-4 GB of VRAM is sufficient. This will allow you to play most modern games at 1080p with decent frame rates (around 30-60 FPS).\\n* For more demanding 1080p gaming (high graphics settings): 6-8 GB of VRAM is recommended. This will provide a smoother gaming experience with higher frame rates (around 60-120 FPS) and more detailed graphics.\\n* For very demanding 1080p gaming (ultra-high graphics settings, high refresh rates, or multiple monitors): 8-12 GB of VRAM or more may be necessary.\\n\\nKeep in mind that these are general guidelines, and the specific VRAM requirements can vary depending on the game and your system's configuration. Some games may require more VRAM than others, even at 1080p.\\n\\nIt's also worth noting that having more VRAM than you need won't necessarily improve performance, but it can provide a buffer for future games that may require more memory. Additionally, other factors like the GPU's processing power, CPU, and system RAM also play a significant role in determining gaming performance.\\n\\nTo give you a better idea, here are some examples of popular graphics cards and their VRAM:\\n\\n* NVIDIA GeForce GTX 1660: 6 GB GDDR6\\n* NVIDIA GeForce RTX 2060: 6 GB GDDR6\\n* AMD Radeon RX 5600 XT: 6 GB GDDR6\\n* NVIDIA GeForce GTX 1070: 8 GB GDDR5\\n\\nIn summary, for 1080p gaming, 6-8 GB of VRAM is a good starting point, but the specific requirements can vary depending on your gaming needs and system configuration.\"\n",
      "    },\n",
      "    {\n",
      "        \"model\": \"AllenAI: Molmo2 8B (free)\",\n",
      "        \"response\": \"For **1080p VR gaming**, **8GB of VRAM** is typically sufficient for most modern titles, especially with medium-to-high settings. You may be able to get away with 6GB in some cases, but 8GB is now considered standard for budget-friendly rigs and can handle most popular 1080p games with decent performance. If you want higher performance or plan on using ray tracing, **16GB of VRAM** is preferred.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(evaluator.user_query_answers, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11482bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"evaluated_model\": \"Meta: Llama 3.3 70B Instruct (free)\",\n",
      "        \"evaluating_model\": \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
      "        \"score\": 85,\n",
      "        \"reasoning\": \"Response provides generally accurate VRAM recommendations with minor underestimation at lower tiers (2-4GB being borderline adequate for modern titles) and one non-critical GDDR spec error (GTX 1070 highlighted as GDDR5 instead of GDDR5X), but demonstrates strong completeness (covers settings tiers and system factors), clarity, and appropriateness - though Correctness deduction dominates due to rubric priority.\"\n",
      "    },\n",
      "    {\n",
      "        \"evaluated_model\": \"AllenAI: Molmo2 8B (free)\",\n",
      "        \"evaluating_model\": \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
      "        \"score\": 84,\n",
      "        \"reasoning\": \"The candidate's recommendation of 16GB VRAM for 1080p with ray tracing is factually excessive (inaccuracy in Correctness & Accuracy, weighted 25%), but other elements show solid completeness, clarity, and relevance.\"\n",
      "    },\n",
      "    {\n",
      "        \"evaluated_model\": \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
      "        \"evaluating_model\": \"Meta: Llama 3.3 70B Instruct (free)\",\n",
      "        \"score\": 96,\n",
      "        \"reasoning\": \"The candidate response is evaluated based on the rubric, with high scores in Correctness & Accuracy, Completeness, Clarity & Coherence, Relevance, and Appropriateness for Context, considering the importance of factual accuracy and comprehensive coverage of the query, as per the rubric's defined weightings and criteria.\"\n",
      "    },\n",
      "    {\n",
      "        \"evaluated_model\": \"AllenAI: Molmo2 8B (free)\",\n",
      "        \"evaluating_model\": \"Meta: Llama 3.3 70B Instruct (free)\",\n",
      "        \"score\": 87,\n",
      "        \"reasoning\": \"The candidate response is evaluated based on the rubric, with Correctness & Accuracy being the most critical factor, and considering the response's minor deviation in specifying '1080p VR gaming' instead of just '1080p gaming', it scores high on Correctness & Accuracy, and well on Completeness, Clarity & Coherence, Relevance, Conciseness, and Appropriateness for Context, thus the overall score is calculated as the weighted sum of these dimensions.\"\n",
      "    },\n",
      "    {\n",
      "        \"evaluated_model\": \"TNG: DeepSeek R1T2 Chimera (free)\",\n",
      "        \"evaluating_model\": \"AllenAI: Molmo2 8B (free)\",\n",
      "        \"score\": 93,\n",
      "        \"reasoning\": \"The response is highly accurate about VRAM requirements for 1080p gaming, complete with nuanced recommendations for different scenarios and specific GPU examples. It is logically organized and free of unnecessary details, and its technical depth suits the context. Correctness and Accuracy are weighted highest, so this strong factual precision yields an excellent score.\"\n",
      "    },\n",
      "    {\n",
      "        \"evaluated_model\": \"Meta: Llama 3.3 70B Instruct (free)\",\n",
      "        \"evaluating_model\": \"AllenAI: Molmo2 8B (free)\",\n",
      "        \"score\": 94,\n",
      "        \"reasoning\": \"The candidate responds with factually accurate VRAM recommendations tailored to 1080p gaming, covers key influencing factors, provides examples, and gives relevant examples, achieving high marks across all rubric dimensions but with a slight improvement possible in conciseness.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(evaluator.evaluation_query_answers, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb9c082b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Evaluated Model (Column)</th>\n",
       "      <th>TNG: DeepSeek R1T2 Chimera (free)</th>\n",
       "      <th>Meta: Llama 3.3 70B Instruct (free)</th>\n",
       "      <th>AllenAI: Molmo2 8B (free)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Judge Model (Row)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TNG: DeepSeek R1T2 Chimera (free)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta: Llama 3.3 70B Instruct (free)</th>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AllenAI: Molmo2 8B (free)</th>\n",
       "      <td>93.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluated Model (Column)             TNG: DeepSeek R1T2 Chimera (free)  \\\n",
       "Judge Model (Row)                                                        \n",
       "TNG: DeepSeek R1T2 Chimera (free)                                  NaN   \n",
       "Meta: Llama 3.3 70B Instruct (free)                               96.0   \n",
       "AllenAI: Molmo2 8B (free)                                         93.0   \n",
       "\n",
       "Evaluated Model (Column)             Meta: Llama 3.3 70B Instruct (free)  \\\n",
       "Judge Model (Row)                                                          \n",
       "TNG: DeepSeek R1T2 Chimera (free)                                   85.0   \n",
       "Meta: Llama 3.3 70B Instruct (free)                                  NaN   \n",
       "AllenAI: Molmo2 8B (free)                                           94.0   \n",
       "\n",
       "Evaluated Model (Column)             AllenAI: Molmo2 8B (free)  \n",
       "Judge Model (Row)                                               \n",
       "TNG: DeepSeek R1T2 Chimera (free)                         84.0  \n",
       "Meta: Llama 3.3 70B Instruct (free)                       87.0  \n",
       "AllenAI: Molmo2 8B (free)                                  NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cc8a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
