# LM-Compass

## Overview

An objective evaluation tool for LLMs &amp; SLMs, designed to address the challenge of AI response accuracy. Users submit a query to get responses from multiple models, which then peer-review each other to find the consensus best answer. The tool provides a quantifiable measure of model performance intended for general AI users and researchers.

## Getting Started

To run the LM-Compass application locally,

```bash
git clone git@github.com:LMCompass/LM-Compass.git
cd lm-compass
npm run dev
```
